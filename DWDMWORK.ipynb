{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN9gmuB4vpK9msbXm7fJLNl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yesubabu0826/FML/blob/main/DWDMWORK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1\n",
        "# Aim: Demonstrate the following data pre-processing tasks using python libraries\n",
        "#     a) loading the dataset\n",
        "#     b) identifying the dependent and independent variable\n",
        "#     c) dealing with missing data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "zNz6-9uVdIr4",
        "outputId": "8b187d08-f455-48f9-b2ba-0ec86f1b31f5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-11-40421f63af70>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-40421f63af70>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    Aim: Demonstrate the following data pre-processing tasks using python libraries\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4_vwi17X9WH",
        "outputId": "9a5cf7b8-f336-48d5-fe76-70266c973f65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      RM  LSTAT  PTRATIO    MEDV\n",
            "0  6.575   4.98     15.3  504000\n",
            "1  6.421   9.14     17.8  453600\n",
            "2  7.185   4.03     17.8  728700\n",
            "3  6.998   2.94     18.7  701400\n",
            "4  7.147   5.33     18.7  760200\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset (change 'file_path' to your file location)\n",
        "file_path = 'your_dataset.csv'\n",
        "data = pd.read_csv(\"/content/housing.csv\")\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the last column is the dependent variable\n",
        "dependent_variable = data.columns[-1]\n",
        "independent_variables = data.columns[:-1]\n",
        "\n",
        "print(\"Dependent Variable:\", dependent_variable)\n",
        "print(\"Independent Variables:\", independent_variables)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5Jw4XofYpiu",
        "outputId": "359a6a76-6784-4b92-e35b-31fea28cf04b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependent Variable: MEDV\n",
            "Independent Variables: Index(['RM', 'LSTAT', 'PTRATIO'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with any missing values\n",
        "data_without_missing = data.dropna()\n",
        "\n",
        "# Fill missing values with a specific value (e.g., 0)\n",
        "data_filled = data.fillna(0)\n",
        "print(data_without_missing )\n",
        "print(data_filled  )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0TtADiPZHF9",
        "outputId": "a73ec873-b332-4a74-ff52-ffebd10406ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        RM  LSTAT  PTRATIO    MEDV\n",
            "0    6.575   4.98     15.3  504000\n",
            "1    6.421   9.14     17.8  453600\n",
            "2    7.185   4.03     17.8  728700\n",
            "3    6.998   2.94     18.7  701400\n",
            "4    7.147   5.33     18.7  760200\n",
            "..     ...    ...      ...     ...\n",
            "484  6.593   9.67     21.0  470400\n",
            "485  6.120   9.08     21.0  432600\n",
            "486  6.976   5.64     21.0  501900\n",
            "487  6.794   6.48     21.0  462000\n",
            "488  6.030   7.88     21.0  249900\n",
            "\n",
            "[489 rows x 4 columns]\n",
            "        RM  LSTAT  PTRATIO    MEDV\n",
            "0    6.575   4.98     15.3  504000\n",
            "1    6.421   9.14     17.8  453600\n",
            "2    7.185   4.03     17.8  728700\n",
            "3    6.998   2.94     18.7  701400\n",
            "4    7.147   5.33     18.7  760200\n",
            "..     ...    ...      ...     ...\n",
            "484  6.593   9.67     21.0  470400\n",
            "485  6.120   9.08     21.0  432600\n",
            "486  6.976   5.64     21.0  501900\n",
            "487  6.794   6.48     21.0  462000\n",
            "488  6.030   7.88     21.0  249900\n",
            "\n",
            "[489 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data' is your DataFrame\n",
        "# Check for missing values in the entire DataFrame\n",
        "missing_values = data.isnull()\n",
        "\n",
        "# Count missing values in each column\n",
        "missing_values_count = data.isnull().sum()\n",
        "\n",
        "# Display missing values count per column\n",
        "print(\"Missing Values Count Per Column:\")\n",
        "print(missing_values_count)\n",
        "\n",
        "# Display locations of missing values (True indicates missing)\n",
        "print(\"Locations of Missing Values:\")\n",
        "print(missing_values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chpXpcV4ZyYw",
        "outputId": "fe113283-d150-4d41-b06d-a7678c232e63"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values Count Per Column:\n",
            "RM         0\n",
            "LSTAT      0\n",
            "PTRATIO    0\n",
            "MEDV       0\n",
            "dtype: int64\n",
            "Locations of Missing Values:\n",
            "        RM  LSTAT  PTRATIO   MEDV\n",
            "0    False  False    False  False\n",
            "1    False  False    False  False\n",
            "2    False  False    False  False\n",
            "3    False  False    False  False\n",
            "4    False  False    False  False\n",
            "..     ...    ...      ...    ...\n",
            "484  False  False    False  False\n",
            "485  False  False    False  False\n",
            "486  False  False    False  False\n",
            "487  False  False    False  False\n",
            "488  False  False    False  False\n",
            "\n",
            "[489 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2\n",
        "# Aim: Demonstrate the following data pre-processing tasks using python libraries\n",
        "#     a) dealing with categorical data\n",
        "#     b) scaling the features\n",
        "#     c) splitting dataset into training and testing sets"
      ],
      "metadata": {
        "id": "XlXa845Lvikt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Load the breast cancer dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Convert the dataset to a DataFrame\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"Initial Dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Splitting the dataset into features and target\n",
        "X = df.drop('target', axis=1)  # Features\n",
        "y = df['target']  # Target variable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7iSlW-JvlTv",
        "outputId": "ef601305-cebd-4782-92d5-09dc137aba1c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Dataset:\n",
            "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0        17.99         10.38          122.80     1001.0          0.11840   \n",
            "1        20.57         17.77          132.90     1326.0          0.08474   \n",
            "2        19.69         21.25          130.00     1203.0          0.10960   \n",
            "3        11.42         20.38           77.58      386.1          0.14250   \n",
            "4        20.29         14.34          135.10     1297.0          0.10030   \n",
            "\n",
            "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0           0.27760          0.3001              0.14710         0.2419   \n",
            "1           0.07864          0.0869              0.07017         0.1812   \n",
            "2           0.15990          0.1974              0.12790         0.2069   \n",
            "3           0.28390          0.2414              0.10520         0.2597   \n",
            "4           0.13280          0.1980              0.10430         0.1809   \n",
            "\n",
            "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
            "0                 0.07871  ...          17.33           184.60      2019.0   \n",
            "1                 0.05667  ...          23.41           158.80      1956.0   \n",
            "2                 0.05999  ...          25.53           152.50      1709.0   \n",
            "3                 0.09744  ...          26.50            98.87       567.7   \n",
            "4                 0.05883  ...          16.67           152.20      1575.0   \n",
            "\n",
            "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
            "0            0.1622             0.6656           0.7119                0.2654   \n",
            "1            0.1238             0.1866           0.2416                0.1860   \n",
            "2            0.1444             0.4245           0.4504                0.2430   \n",
            "3            0.2098             0.8663           0.6869                0.2575   \n",
            "4            0.1374             0.2050           0.4000                0.1625   \n",
            "\n",
            "   worst symmetry  worst fractal dimension  target  \n",
            "0          0.4601                  0.11890       0  \n",
            "1          0.2750                  0.08902       0  \n",
            "2          0.3613                  0.08758       0  \n",
            "3          0.6638                  0.17300       0  \n",
            "4          0.2364                  0.07678       0  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(\"\\nProcessed Dataset - Scaled Features:\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGU-_p_xvu4s",
        "outputId": "198cf7ca-23b5-430f-8b6c-d947b6eb60c8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed Dataset - Scaled Features:\n",
            "X_train shape: (398, 30)\n",
            "X_test shape: (171, 30)\n",
            "y_train shape: (398,)\n",
            "y_test shape: (171,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 3\n",
        "# Aim: Demonstrate the following similarity and dissimilarity measures using python\n",
        "#     a) cosine similarity\n",
        "#     b) Euclidean distance\n",
        "#     c) Pearson's corelation\n",
        "#     d) Jaccard similarity\n",
        "#     e) Manhattan distance"
      ],
      "metadata": {
        "id": "9XSZsAJQvys9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import euclidean, cityblock\n",
        "from scipy.stats import pearsonr\n",
        "import numpy as np\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "data = iris.data\n",
        "\n",
        "# Sample indices for demonstration\n",
        "index1, index2 = 0, 1  # Selecting two samples from the dataset\n",
        "\n",
        "# Select two samples from the Iris dataset\n",
        "sample1 = data[index1]\n",
        "sample2 = data[index2]\n",
        "print(sample1)\n",
        "print(sample2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3d_geSlwFme",
        "outputId": "3489c984-909b-4db8-efa0-016d02bf4f55"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5.1 3.5 1.4 0.2]\n",
            "[4.9 3.  1.4 0.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute cosine similarity\n",
        "cosine_sim = cosine_similarity([sample1], [sample2])\n",
        "print(f\"Cosine Similarity between sample {index1} and sample {index2}: {cosine_sim[0][0]}\")\n",
        "\n",
        "# Compute Euclidean distance\n",
        "euclidean_dist = euclidean(sample1, sample2)\n",
        "print(f\"Euclidean Distance between sample {index1} and sample {index2}: {euclidean_dist}\")\n",
        "\n",
        "# Compute Pearson's correlation coefficient\n",
        "correlation_coefficient, _ = pearsonr(sample1, sample2)\n",
        "print(f\"Pearson's Correlation Coefficient between sample {index1} and sample {index2}: {correlation_coefficient}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VMWp_czwOKU",
        "outputId": "278b0831-278c-484b-ea76-49161b632fef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity between sample 0 and sample 1: 0.9985791635040219\n",
            "Euclidean Distance between sample 0 and sample 1: 0.5385164807134502\n",
            "Pearson's Correlation Coefficient between sample 0 and sample 1: 0.99599866124026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert the samples to sets for Jaccard similarity\n",
        "set1 = set(sample1)\n",
        "set2 = set(sample2)\n",
        "\n",
        "# Compute Jaccard similarity\n",
        "jaccard_similarity = len(set1.intersection(set2)) / len(set1.union(set2))\n",
        "print(f\"Jaccard Similarity between sample {index1} and sample {index2}: {jaccard_similarity}\")\n",
        "\n",
        "# Compute Manhattan distance\n",
        "manhattan_dist = cityblock(sample1, sample2)\n",
        "print(f\"Manhattan Distance between sample {index1} and sample {index2}: {manhattan_dist}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5uOeSp9wRIZ",
        "outputId": "4b979052-a80e-41c7-ae1f-ea0814e09f06"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard Similarity between sample 0 and sample 1: 0.3333333333333333\n",
            "Manhattan Distance between sample 0 and sample 1: 0.6999999999999993\n"
          ]
        }
      ]
    }
  ]
}